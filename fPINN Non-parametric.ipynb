{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключение библиотек ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from scipy.special import gamma,erfc\n",
    "from scipy.integrate import quad\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from pyfod.fod import caputo\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройка СUDA ##  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    dev = \"cuda:0\" \n",
    "else: \n",
    "    dev = \"cpu\" \n",
    "device = torch.device(dev) \n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция Миттаг-Леффлера ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLF(z, alpha, N=10000):\n",
    "    # tic = time.perf_counter()\n",
    "\n",
    "    # Преобразование типов данных\n",
    "    if not isinstance(z, np.ndarray):\n",
    "        if isinstance(z, torch.Tensor):\n",
    "            z = z.numpy()\n",
    "        else:\n",
    "            z = np.array(z)\n",
    "    z = np.atleast_1d(z)\n",
    "    \n",
    "    # Случаи для различных параметров alpha\n",
    "    if alpha == 0:\n",
    "        return 1/(1 - z)\n",
    "    elif alpha == 1:\n",
    "        return np.exp(z)\n",
    "    elif alpha == 1/2:\n",
    "        return np.exp(z ** 2) * erfc(-z)\n",
    "    elif alpha > 1 or all(z > 0):\n",
    "        k = np.arange(N)\n",
    "        return np.polynomial.polynomial.polyval(z, 1 / gamma(alpha * k + 1))\n",
    "        # j = np.arange(N).reshape(-1, 1)\n",
    "        # E = (np.power(z, j)) / gamma(alpha * j + 1)\n",
    "        # return torch.tensor(np.sum(E, axis=0))\n",
    "\n",
    "    def _MLF(z, alpha):\n",
    "        if z < 0:\n",
    "            def f(x): return ((np.exp(-x * np.power(-z, 1 / alpha)) * np.power(x, alpha - 1) * np.sin(np.pi * alpha))\n",
    "                    / (np.power(x, 2 * alpha) + 2 * np.power(x, alpha) * np.cos(np.pi * alpha) + 1))\n",
    "            return 1 / np.pi * quad(f, 0, np.inf)[0]\n",
    "        elif z == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return MLF(z, alpha)\n",
    "\n",
    "    # toc = time.perf_counter()\n",
    "    # print(f\"Time = {toc-tic}\")\n",
    "    return np.vectorize(_MLF)(z, alpha)\n",
    "\n",
    "\n",
    "res = MLF(1, 1)\n",
    "print(f\"MLF = {res}, type={type(res)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "x = np.linspace(-10, 1, 100)\n",
    "plt.grid()\n",
    "for i in range(1, 11):\n",
    "    plt.plot(x, MLF(x, i/10), label=\"alpha = \"+str(i/10))\n",
    "plt.legend()\n",
    "plt.ylim(-2, 5)\n",
    "plt.xlim(x[0], x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "x = np.linspace(-10, 1, 100)\n",
    "plt.grid()\n",
    "plt.plot(x, MLF(x, 0.1), label=\"alpha = 0.1\")\n",
    "plt.legend()\n",
    "plt.ylim(-2, 5)\n",
    "plt.xlim(x[0], x[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметры задач ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_lin = 0.5\n",
    "y0_lin = 1\n",
    "m_lin = 1\n",
    "\n",
    "lambda_nonlin = 0.5\n",
    "y0_nonlin = 0\n",
    "m_nonlin = 0.5\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Точные решения ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_lin(x, alpha):\n",
    "    solution = y0_lin * ml(lambda_lin * np.power(x, alpha), alpha)\n",
    "    return solution\n",
    "\n",
    "def solution_nonlin(x, alpha):\n",
    "    gm = alpha / (1 - m_nonlin)\n",
    "    tmp = gamma(gm + 1) / (lambda_nonlin * gamma(gm - alpha + 1))\n",
    "    B = np.power(tmp, 1 / (m_nonlin - 1))\n",
    "    solution = B * np.power(x, gm)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Equations = {\"Linear\" : (y0_lin, lambda_lin, m_lin, solution_lin), \"Nonlinear\" : (y0_nonlin, lambda_nonlin, m_nonlin, solution_nonlin)}\n",
    "Equations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.linspace(0, 1, 1000)\n",
    "# plt.grid()\n",
    "# plt.plot(x, Equations['Linear'][3](x, 0.1))\n",
    "# plt.plot(x, Equations['Nonlinear'][3](x, 0.1))\n",
    "# plt.legend(Equations.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель нейронной сети ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_hidden, size_hidden, activation=nn.Tanh()):\n",
    "        super(Net, self).__init__()\n",
    "        self.activation_function = activation\n",
    "\n",
    "        self.layer_input = nn.Linear(1, size_hidden).double()\n",
    "        self.hidden_layers = nn.ModuleList(\n",
    "            [nn.Linear(size_hidden, size_hidden).double() for _ in range(num_hidden - 1)])\n",
    "        self.layer_output = nn.Linear(size_hidden, 1).double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.type(torch.double)\n",
    "        x = self.layer_input(x)\n",
    "        x = self.activation_function(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "            x = self.activation_function(x)\n",
    "        output = self.layer_output(x)\n",
    "        return output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация весов ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Текущий результат работы сети ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_fn(nn, x):\n",
    "    return nn(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление производной ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df(nn, alpha, x):\n",
    "    def f(x):\n",
    "        x = torch.from_numpy(x)\n",
    "        return net_fn(nn, x)\n",
    "    result = torch.zeros(x.shape)\n",
    "    for k in range(len(x)):\n",
    "        fd = caputo(f=f, alpha=alpha, lower=0, upper=x[k], quadrature='rs', n=100)\n",
    "        result[k] = fd['fd']\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция ошибки ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(nn, alpha, x=None, verbose=False):\n",
    "    lin = problem\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "    # Начальное условие\n",
    "    initial_condition = Equations[lin][0]\n",
    "    initial_loss = net_fn(nn, x[0]) - initial_condition\n",
    "    initial_loss = mse_loss(initial_loss, torch.zeros_like(initial_loss))\n",
    "    \n",
    "    # Внутренняя ошибка\n",
    "    lmbd = Equations[lin][1]\n",
    "    m = Equations[lin][2]\n",
    "    \n",
    "    interior_loss = df(nn, alpha, x[1:]) - lmbd * torch.pow(torch.abs(net_fn(nn, x[1:])), m)  \n",
    "    interior_loss = mse_loss(interior_loss, torch.zeros_like(interior_loss))\n",
    "\n",
    "    # print(f\"Initial loss: {initial_loss}\")\n",
    "    # print(f\"Interior loss: {interior_loss}\")\n",
    "    \n",
    "    loss = initial_loss + interior_loss\n",
    "    return loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цикл обучения ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(nn, alpha, loss_fn, optimizer, scheduler=None, n_epochs=1000):\n",
    "    train_loss = torch.zeros(n_epochs)\n",
    "    \n",
    "    def closure():\n",
    "        if torch.is_grad_enabled():\n",
    "            optimizer.zero_grad()\n",
    "        loss = loss_fn(nn, alpha)\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "        return loss\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "                       \n",
    "        if isinstance(optimizer, torch.optim.LBFGS):\n",
    "            optimizer.step(closure)\n",
    "            loss = closure()\n",
    "        else:\n",
    "            loss = loss_fn(nn, alpha)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss)\n",
    "            \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, learning rate = {optimizer.param_groups[-1]['lr']}, loss={loss},\\n\")\n",
    "                 \n",
    "    return nn, train_loss      \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение сети ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гиперпараметры сети ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 'Nonlinear'\n",
    "num_hidden = 1\n",
    "size_hidden = 60\n",
    "activation_function = nn.Tanh()\n",
    "\n",
    "NN = Net(num_hidden, size_hidden, activation_function)\n",
    "NN.apply(init_weights)\n",
    "\n",
    "learning_rate_Adam = 0.01\n",
    "learning_rate_LBFGS = 0.01\n",
    "epochs = 1000\n",
    "alpha = 0.1\n",
    "\n",
    "optimizer_adam = torch.optim.AdamW(NN.parameters(), lr=learning_rate_Adam, weight_decay=0.00001)\n",
    "scheduler_adam = ReduceLROnPlateau(optimizer_adam, 'min', factor=0.1, patience=1000, min_lr=1e-6)\n",
    "\n",
    "optimizer_lbfgs = torch.optim.LBFGS(NN.parameters(), lr=learning_rate_LBFGS)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тренировка на заданном интервале ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 1, 10).reshape(-1, 1)\n",
    "loss_fn = partial(loss_function, x=x, verbose=True)\n",
    "\n",
    "PINN_Adam, train_loss_Adam = training_loop(\n",
    "    nn=NN,\n",
    "    alpha=alpha,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer_adam,\n",
    "    scheduler=scheduler_adam,\n",
    "    n_epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PINN_LBFGS, train_loss_LBFGS = training_loop(\n",
    "#     nn=PINN_Adam,\n",
    "#     alpha=alpha,\n",
    "#     loss_fn=loss_fn,\n",
    "#     optimizer=optimizer_lbfgs,\n",
    "#     n_epochs=1000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINN = PINN_Adam\n",
    "x_eval = torch.linspace(0, 1, 1000).reshape(-1, 1)\n",
    "nn_approx = PINN(x_eval).detach().numpy()\n",
    "sol = Equations[problem][3](x_eval, alpha)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка качества модели ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(solution, approximation):\n",
    "    if isinstance(solution, torch.Tensor):\n",
    "        solution = solution.detach().numpy()\n",
    "    if np.any(np.isnan(approximation)):\n",
    "        return np.nan, np.nan, np.nan\n",
    "    MAE = mean_absolute_error(solution[1:], approximation[1:])\n",
    "    MRE = np.mean(np.fabs(approximation[1:] - solution[1:]) / np.fabs(solution[1:])) * 100\n",
    "    InitLoss = float(np.fabs(solution[0] - approximation[0]))\n",
    "    # print(f\"Mean absolute error (MAE) = {MAE:.5}\\nMean relative error (MRE) = {MRE:.5}%\\nLoss on initial condition = {InitLoss:.5}\")\n",
    "    return MAE, MRE, InitLoss\n",
    "\n",
    "# MAE, MRE, InitLoss = error(sol, nn_approx)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отрисовка графиков ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(x, solution, approximation, name=None):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim(-0.1, 1.1)\n",
    "    \n",
    "    plt.plot(x, approximation, '-.', label='PINN')\n",
    "    plt.plot(x, solution, label='Solution')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    MAE, MRE, InitLoss = error(solution, approximation)\n",
    "    plt.title(f\"Mean absolute error (MAE) = {MAE:.5}\\nLoss on initial condition = {InitLoss:.5}\")\n",
    "    # plt.text(0.4, solution[0], f\"Mean absolute error (MAE) = {MAE:.5}\\nLoss on initial condition = {InitLoss:.5}\",\n",
    "    #          bbox={\"fill\": False})\n",
    "\n",
    "    if name is not None:\n",
    "        plt.savefig(f\"{name}.png\")\n",
    "    \n",
    "    # plt.cla()\n",
    "    return MAE, MRE, InitLoss\n",
    "    \n",
    "# plot_graph(x_eval, sol, nn_approx, train_loss_Adam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тесты ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "\n",
    "problem = 'Nonlinear'\n",
    "N = 1\n",
    "num_hidden = 1\n",
    "size_hidden = 80\n",
    "\n",
    "activation_function = nn.Tanh()\n",
    "learning_rate_Adam = 0.01\n",
    "epochs = 40000\n",
    "\n",
    "alphas = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]\n",
    "x_eval = torch.linspace(0, 1, 1000).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "columns = {\"Hidden layers\": [], \"Neurons in HL\": [], \"Activation function\": [],\n",
    "                        \"Learning rate\": [], \"N_x\": [], \"Epochs\": [], \"Alpha\": [], \"MAE\": [],\n",
    "                        \"InitLoss\": [], \"Time\" : []}\n",
    "Test_data = pd.DataFrame(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "Test = 1\n",
    "x = torch.linspace(0, 1, 40).reshape(-1, 1)\n",
    "loss_fn = partial(loss_function, x=x, verbose=True)\n",
    "for alpha in alphas:\n",
    "    MAE = np.zeros(N)\n",
    "    InitLoss = np.zeros(N)\n",
    "    Time = np.zeros(N)\n",
    "    for k in range(N):\n",
    "        \n",
    "        NN = Net(num_hidden, size_hidden, activation_function)\n",
    "        NN.apply(init_weights)\n",
    "        \n",
    "        optimizer_adam = torch.optim.AdamW(NN.parameters(), lr=learning_rate_Adam, weight_decay=0.00001) \n",
    "        scheduler = ReduceLROnPlateau(optimizer_adam, 'min', factor=0.1, patience=4000, min_lr=1e-6)\n",
    "        \n",
    "        tic = time.perf_counter()\n",
    "        PINN_Adam, train_loss_Adam = training_loop(\n",
    "            nn=NN,\n",
    "            alpha=alpha,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer_adam,\n",
    "            scheduler=scheduler,\n",
    "            n_epochs=epochs\n",
    "        )\n",
    "        toc = time.perf_counter()\n",
    "        Time[k] = toc - tic\n",
    "        \n",
    "        PINN = PINN_Adam\n",
    "        nn_approx = PINN(x_eval).detach().numpy()\n",
    "        sol = Equations[problem][3](x_eval, alpha)\n",
    "        MAE[k], MRE, InitLoss[k] = plot_graph(x_eval, sol, nn_approx, f\"{alpha}_{k}\")\n",
    "        torch.save(PINN_Adam, f\"{problem}_alpha_{alpha}_{k}.pth\")\n",
    "        \n",
    "    tmp = {\"Hidden layers\": num_hidden, \"Neurons in HL\": size_hidden, \"Activation function\": \"Tanh\",\n",
    "                        \"Learning rate\": learning_rate_Adam, \"N_x\": 40, \"Epochs\": epochs, \"Alpha\": alpha, \"MAE\": MAE.mean(),\n",
    "                        \"InitLoss\": InitLoss.mean(), \"Time\" : Time.mean()}\n",
    "    Test_data = pd.concat([Test_data, pd.DataFrame.from_records([tmp])], ignore_index=True)\n",
    "    Test_data.to_excel(f\"Alphas_{problem}_{N}_realizations.xlsx\")\n",
    "    print(f\"Test {Test} completed.\\n\")\n",
    "    Test += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
